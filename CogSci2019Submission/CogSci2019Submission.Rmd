---
title: "Parents' Linguistic Alignment Predicts Children's Language Development"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
 \author{Joseph Denby \and Daniel Yurovsky \\
         \texttt{\{jgdenby, yurovsky\}@uchicago.edu} \\
        Department of Psychology \\ University of Chicago}

abstract: >
    Children quickly gain enormous linguistic knowledge during early development, in part due to low-level features of their parents' speech. Some posit that parents contribute to their child's language development by calibrating their language according to their child's developmental abilities and needs. Here, we investigate this hypothesis by examining 'alignment' at the level of syntax in a large-scale corpus of parent-child conversations and measuring its association with language development outcomes. To do so, we employ a statistical model of alignment to estimate its presence in our dataset and its impact on language development outcome measures. Our results corroborate previous findings, showing strong alignment for both parents and children; in addition, we demonstrate that parental alignment is a significant predictor of language maturity independent of demographic features, suggesting that parents' tuning has strong ties to their children's language development. 
    
keywords: >
    Language acquisition; computational modeling; cognitive development
    
output: cogsci2016::cogsci_paper
# final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(feather)
library(tidyverse)
library(magrittr)
library(rstan)
library(latex2exp)
library(here)
library(directlabels)
library(ggthemes)
library(anonymizer)

theme_set(theme_classic(base_size = 10))
```


```{r, raw_data, eval = F}
long_present <- read_feather(here("data/ppvt_with_demos.feather"))

demos <- long_present %>%
  distinct(subject, income_category, mother_education, sex, race, ethn, session) %>%
  group_by(subject, income_category, mother_education, sex, race, ethn) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  mutate(subject = salt(subject, .seed = 400)) %>%
  mutate(subject = as.numeric(as.factor(subject))) 

write_csv(demos, "data/demos.csv")

liwc <- read_tsv("word_lists/liwc2007_converted.tsv", col_names = FALSE) %>%
  rename(word = X1, category = X2)

liwc_cats <- liwc %>%
  select(category) %>%
  distinct()

# sample <- liwc %>%
#   group_by(category) %>%
#   filter(!str_detect(word, '\\*')) %>%
#   sample_n(2) %>% 
#   group_by(category) %>%
#   mutate(examples = paste0(word, collapse=', ')) %>%
#   select(category, examples) %>%
#   distinct()
#   
# write_feather(sample, '../liwc_sample_table.feather')
```

# Introduction 

Children make vast linguistic strides within their first few years of life, rapidly growing their vocabulary [@Mayor:2010kp].
<!-- and acquiring an understanding of compositional structure [@Lieven:2009ii].To explore this feat, many have probed the role of statistical learning in features of language development, such as detecting words [@Anonymous:6O2YEUCo], grammar [@Gomez:1999bx], and semantics [@Naigles:1990cw; @OVIDDS:2009uz; @Smith:2008gp]. -->
Some researchers have put forward the linguistic tuning hypothesis, arguing that parents bolster their child's early language learning by calibrating the complexity of their speech to the particular abilities and needs of their children [@Montag:2015iy; @Snow:2018wf; @Thiessen:2005tx]. The idea is intuitive, but it is unclear at what level tuning occurs [@Hayes:1988ue; @Sokolov:1993cr; @Spivey:2006fa] and how overt it is [@Brown:1970wd; @Chouinard:2003kq; @HirshPasek:1984bd].

A parallel yet complementary vein of language development research investigates the presence of low-level cues in parental speech and their influence on child language learning. From this research, we know that child-directed speech contains features that facilitate language learning, and that more exposure tends to result in better outcomes  [@CameronFaulkner:2003ge; @Weisleder:2013ht]. Related, caregivers from families of high socioeconomic status (SES) tend to
converse more with their children than their lower SES counterparts, and these increases are associated with improved development outcomes such as vocabulary size and school performance [@Hoff:2003kx; @Anonymous:GIFaG1Qd]. Moreover, differences in SES-based language development are largely explained by low-level features of parental child-directed speech such as lexical diversity and sentence complexity [@HoffGinsberg:2008up;@ROWE:2008go]. So, given that granular aspects of parent speech can have substantial effects on a child's language development, it may be that linguistic tuning occurs at this level in subtle ways, particularly when it comes to non-content words (i.e., words
that are not central to the topic of discussion.)  
  
This idea of assessing the direct impact of a parent's usage of non-content word on language development relates to linguistic alignment, a phenomenon whereby
conversational partners tend to align aspects of their communicative style and content according to
various external influences e.g., [@Pennebaker:kqtgxul0]. @Anonymous:r2JoRscQ investigates linguistic alignment in CHILDES [@MacWhinney:2000jx], a natural language
corpus of conversation between parents and children  to assess whether tuning occurs at the level of syntactic categories. They find that syntactic alignment does occur between both parents and children; moreover, parents align less over time, suggesting that the relationship their speech shares with their child's changes as a function of development. These results present a powerful proof of concept that syntactic alignment exists between parents and children and changes over time, but it remains unclear whether alignment bears any sort of concrete, impactful relationship to language development.

Here, we extend Yurovsky, Doyle, and Frank's -@Anonymous:r2JoRscQ model by applying it to the Language Development
Project (LDP) [@GoldinMeadow:2014hr], a corpus of
ecological conversations between parents and their children over time, collected from a
socioeconomically diverse sample of parent-child dyads. Moreover, we use alignment estimates alongside demographic information to predict language outcome measures, strengthening the linguistic tuning hypothesis by concretely showing how parents' sensitivity to their child's linguistic needs and abilities impacts their development. 

# Model

The linguistic tuning hypothesis predicts that parents will calibrate their language in part by assessing their child's needs and abilities. So, we predict that parents will exhibit high alignment to their young children, but will reduce their alignment as their children mature. To test this prediction, we employ an extended version of the Hierarchical Alignment Model (HAM) implemented in @Anonymous:r2JoRscQ which both estimates the impact of a speaker's use of syntactic categories on their conversational partner's usage and uses these alignment estimates to predict language outcome scores. 
  
At base, the model predicts, for each utterance, whether the speaker will produce a word from a given syntactic category. This prediction is generated by two factors: the speaker's baseline propensity towards using that category and the speaker's tendency to align, producing words from a category just used by their partner. In the model, the primary computation mimics a standard logistic regression - the production of a syntactic category within an utterance is treated as a binary outcome variable impacted by a linear combination of predictor variables (here, baseline usage and alignment.) The model's hierarchical structure then allows the estimates of baseline usage and alignment effects to be pooled across individual speakers and syntactic categories in a way that ensures statistical robustness.

The model used here then incorporates these alignment and baseline usage estimates as predictors in a linear regression model of PPVT [@PeabodyPictureVoca:im]. At this stage, PPVT is estimated as a linear combination of predictors reflecting alignment and baseline usage estimate for both parents and children alongside other predictors representing demographic variables (e.g., child's gender, mother's education) and the child's age.

```{r liwc xtable, results = 'asis'}
sample <- read_feather(here('liwc_sample_table.feather'))

sample_table <- sample %>% 
  xtable::xtable(.,caption = 'LIWC Categories with example words.')

print(sample_table, type="latex", comment = F, table.placement = "H")
```


## Model Details

The structure of the model used here greatly resembles that used in @Anonymous:r2JoRscQ, in that it operates over utterances represented as binary vectors, with indices indicating the presence or absence of each of the 14 LIWC categories (Table 1). The probability of producing each category in each utterance is predicted from two parameters: the speaker's baseline usage of that syntactic category ($\eta^{base}$), and the change in that speaker's baseline as a function of interacting with the listener ($\eta^{align}$). So, for a given syntactic category $c$, for replies to utterances that don't contain $c$, the production parameter for that category is computed by applying the inverse logit function to the appropriate baseline log odds:
$$
P(Production_c) = logit^{-1}(\eta^{base}_c)
$$
Alternatively, replies to utterances that *do* contain $c$, the parameter computation takes into account the sum of the baseline and alignment log odds:
$$
P(Production_c) = logit^{-1}(\eta^{base}_c+\eta^{align}_c)
$$  
   
To accommodate the variance in production across the LIWC categories, each baseline usage parameter was drawn from an uninformative prior ($\eta^{base} \sim Uniform(-5,5)$); alignment parameters were regularized towards 0 by way of implementing a conservative prior ($\eta^{align} \sim Normal(0,.25)$).  
  
All parameters were estimated hierarchically, which allows intelligent pooling of data across participants in the dataset. To start, each subpopulation (i.e., parents vs. children) obtained an estimate. Then, every speaker had an alignment estimate drawn from their appropriate subpopulation (e.g., if Speaker 22 is a child, their alignment estimate is drawn from the estimate for children overall.) Category-level alignment estimates were then drawn for each speaker (e.g., the alignment estimate for Speaker 22's usage of determiners is drawn from Speaker 22's alignment estimate.) The order was flipped for baseline estimates in order to better reflect empirical baseline usages across syntactic categories; subpopulation estimates produced category-level estimates, which then produced speaker-level estimates. As in @Anonymous:r2JoRscQ, we also include parameters that allow baseline and alignment probabilities to change linearly over time($\beta$ and $\alpha$ respectively).  
  
Next, we extend the model used in @Anonymous:r2JoRscQ by using estimated alignment (i.e., $\eta$ parameters) to predict PPVT scores, a widely used inventory for tracking language development [@PeabodyPictureVoca:im]. To do so, we implement a regression model where PPVT scores are modeled as linear combinations of various predictor variables. These predictor variables included the child's age, alignment parameter estimates for the child and their parent, the mother's education, the child's gender, as well as interaction effects for all variables with age. Error variance for the model ($\sigma$) was also estimated.  
  
The model implemented here then serves two purposes: (1) It extends the analysis of @Anonymous:r2JoRscQ to a new dataset, aiming to replicate previous findings in a more diverse and representative sample, and (2) It incorporates alignment estimates in a predictive model of early language outcomes, serving to test the hypothesis that alignment has significant effects on language development over and above demographic features. To be specific, we hope to replicate non-zero estimates for $\eta$ parameters (demonstrating that alignment between parents and children exists across datasets), positive $\beta$ for children (showing that children increase their baseline usage of categories over time), and negative $\alpha$ for parents (showing that parents decrease their alignment as their children age.) If the PPVT model estimates for parameters corresponding to the main or interaction effects of alignment are non-zero in the presence of demographic variables, we can infer that alignment has an relationship with language development independent of features like socioeconomic status, bolstering the linguistic tuning hypothesis. 

```{r read_data}
fit_hierarchical <- readRDS("../hierppvt500iters.rds")
demos <- read_csv("../data/demos.csv")
```

```{r process_demos}
girls <- demos %>% 
  summarise(sex = sum(sex == "F")) %>% 
  pull()

race <- demos %>%
  group_by(race) %>%
  summarise(n = n())

black <- demos %>%
  filter(race == "BL") %>%
  summarise(n = n()) %>%
  pull(n)

mixed <- demos %>%
  filter(race == "2+") %>%
  summarise(n = n()) %>%
  pull(n)

momed <- demos %>%
  group_by(mother_education) %>%
  summarise(n = n())
```

# Analysis

## Data
Conversations between parents and their children were drawn from the Language Development Project Corpus [@GoldinMeadow:2014hr]. Participants in the project were videorecorded in their homes for $\sim$ 90 minutes every four months starting when the child was 14-months and ending at 58-months. Participants were selected in order to produce a diverse sample demographically representative of the broader Chicagoland area. 

We selected for analysis all children who were typically developing and completed at least 10 of the 12 planned recording sessions. Our sample consisted of `r nrow(demos)` target children, `r girls` of whom were girls, `r black` were Black and `r mixed` were Multiracial. Children were also socio-economically diverse, as measured by mother's education: `r momed %>% slice(1) %>% pull(n)` mothers had some highschool education, `r momed %>% slice(2) %>% pull(n)` had a highschool degree, `r momed %>% slice(3) %>% pull(n)` had some college or trade school, `r momed %>% slice(4) %>% pull(n)` had a highschool degree or GED, `r momed %>% slice(4) %>% pull(n)` had college degrees, and `r momed %>% slice(5) %>% pull(n)` had advanced degrees.

Following @Anonymous:r2JoRscQ, successive utterances from a speaker within a transcript were concatenated into a single utterance. Individual utterances were then transformed into binary vectors with indices indicating the presence or absence of each of the 14 LIWC categories. This pre-processing turned every transcript into a speaker-reply format: each utterance within a transcript was both a reply to the preceding utterance and a message to the next one. 
  
  Each transcript was then compressed, yielding 4 numbers for each LIWC category. For a pair of speakers *A* and *B* in a transcript, for each LIWC category, we computed the number of utterances from *A* to *B* containing the category ($N^{align}$), the number of utterances from *A* to *B* not containing the category ($N^{base}$), the number of utterances containing the category responding to an utterance containing the category ($C^{align}$), and the number of utterances containing the category responding to an utterance not containing the category ($C^{base}$). Aggregating in this way provided the platform for the model's sampling - for each transcript, $C^{base}$ and $C^{align}$ were drawn from Binomial distributions parameterized by $N^{base}$ and $N^{align}$ chances respectively, with probabilities computed via the logistic regression models outlined above.  
  Sampling was performed using Stan, a probabilistic programming language that implements Hamiltonian Monte Carlo sampling methods [@Carpenter:2017ke]. Posterior distributions for each parameter in the model were estimated using 500 iterations. \footnote{Data and code available on Github; will be made available at time of acceptance.} 

```{r alignment_analysis_helpers}
speaker_parameters <- c("eta_ab_speaker", "alpha_speaker", "beta_speaker")
subpop_parameters <- c("eta_ab_subpop", "alpha_subpop", "beta_subpop")

ppvt_parameters <- c("ppvt_intercept", "ppvt_age_years", 
                     "ppvt_education", "ppvt_female", "ppvt_child_align", 
                     "ppvt_parent_align", "ppvt_child_align_slope", 
                     "ppvt_parent_align_slope", "ppvt_mother_ed_slope", 
                     "ppvt_female_slope")

CI_UPPER <- .975
CI_LOWER <- .025

SE_UPPER <- .84
SE_LOWER <- .16
  
extract_speaker_samples <- function(model) {

  extract_helper <- function(var) {
    data.frame(extract(model, var)) %>% 
      bind_rows() %>%
      mutate(sample = 1:n()) %>%
      gather_("speaker_num", var, names(.)[1:(length(names(.))-1)]) %>%
      ungroup() %>%
      mutate(speaker_num = as.numeric(sub(paste0(var, "."), "", speaker_num)))
  }
  
  Reduce(left_join, lapply(speaker_parameters, extract_helper))
}

extract_subpop_samples <- function(model) {

  #print(model)
  
  extract_helper <- function(var) {
    data.frame(extract(model, var)) %>% 
      bind_rows() %>%
      mutate(sample = 1:n())
  }
  
  Reduce(left_join, lapply(subpop_parameters, extract_helper))
}

extract_ppvt_samples <- function(model) {

  #print(model)
  
  extract_helper <- function(var) {
    data.frame(extract(model, var)) %>% 
      bind_rows() %>%
      mutate(sample = 1:n())
  }
  
  Reduce(left_join, lapply(ppvt_parameters, extract_helper))
}
```

```{r extract_samples}
subpop_samples <- extract_subpop_samples(fit_hierarchical) %>%
  gather(measure, value, -sample) %>%
  separate(measure, into = c("measure", "subpop"), sep = "\\.") %>%
  spread(measure, value) %>%
  rename(person = subpop) %>%
  mutate(person = factor(person, levels = c(2,1), labels = c("Parent", "Child")))

ppvt_samples <- extract_ppvt_samples(fit_hierarchical) 

# speaker_samples <- extract_speaker_samples(fit_hierarchical) 
#   
#   mutate(samples = map(model, extract_subpop_samples)) %>%
#   select(-data, -model) %>%
#   unnest() %>%
#   left_join(select(model_data, subject, uid) %>% distinct(), 
#             by = c("subpop_num" = "uid")) %>%
#   select(-subpop_num)
```

```{r get_parameters}
parameters <- subpop_samples %>%
  group_by(person) %>%
  gather(parameter, value, -sample, -person) %>%
  group_by(person, parameter) %>%
  summarise(mean = mean(value), ci_lower = quantile(value, CI_LOWER),
            ci_upper = quantile(value, CI_UPPER))

ppvt_parameters <- ppvt_samples %>%
  gather(parameter, value, -sample) %>%
  group_by(parameter) %>%
  summarise(mean = mean(value), ci_lower = quantile(value, CI_LOWER),
            ci_upper = quantile(value, CI_UPPER))

```


## Results

Alignment estimates ($\eta^{align}$) for parents and children were both estimated above zero, corroborating the findings of @Anonymous:r2JoRscQ in showing that both groups exhibit alignment (Figure 1). We also replicate the finding that parents appear to align more to their children than children align to their parents. 
  
  The model estimates developmental baseline changes ($\beta$) at approximately zero for parents, but significantly above zero for children, replicating previous findings. Alignment is estimated as having no significant age effect ($\alpha$) in this dataset, failing to replicate an earlier finding that parents tend to exhibit decreased alignment over their child's development. However, the mean estimate is trending negatively, suggesting this may be a function of the data's limited scope (Figure 2). 

```{r parameters_plot, fig.width=3.25, fig.height=2.25, set.cap.width=T, num.cols.cap=1, cache = T, fig.cap = "Posterior parameter estimates for alignment ($\\eta$), developmental change in alignment ($\\alpha$), and developmental change in baseline function word production ($\\beta$) for both parents and children, as well estimated alignment between parents for a baseline. Bars indicate means, error-bars indicate 95\\% highest posterior density intervals"}
plot_parameters <- parameters %>%
  ungroup() %>%
  mutate(parameter = factor(parameter, 
                            levels = c("eta_ab_subpop","alpha_subpop","beta_subpop"),
                            labels = c("Alignment~(eta^align)","Alignment%.%Age~(alpha)",
                                       "Baseline%.%Age~(beta)")))

ggplot(plot_parameters, aes(x = person, y = mean, fill= person, 
            label = person)) +
  facet_grid(. ~ parameter, scales = "free_x", space = "free_x", 
             labeller = label_parsed) +
  geom_bar(position = position_dodge(.5), stat = "identity") +
  geom_linerange(aes(ymax = ci_upper, ymin = ci_lower),
                   position = position_dodge(.5)) +
  geom_hline(yintercept = 0) + 
  scale_fill_brewer(palette = "Set1", guide = FALSE) +
  scale_x_discrete(name = "", drop = T) +
  scale_y_continuous(name = "Population parameter estimate", limits = c(-.35, .8),
                     breaks = seq(-2, 1, .2)) +
  theme_classic(base_size = 9) +
   theme(panel.grid = element_blank(), legend.position = c(.8,.8),
       axis.title.x=element_text(vjust=-.5), axis.title.y=element_text(vjust=1))
```

The mean estimates for PPVT predictors are presented in Figure 3. PPVT is positively associated with the age of the child and their being female. Moreover, female children tend to have a decreased age effect on PPVT; this means that for female children, the expected increase in PPVT over time is smaller. Mother's education is negatively associated with PPVT, but has a slight positive age effect. Alongside these demographic effects, we see robust alignment effects on PPVT: child and parental alignment are both associated with increased PPVT, but with decreased age effects.
  
```{r coefficients xtable, results = 'asis', eval = F}
ppvt_coefficients <- c("Age (years)", "Child Alignment","Age x Child Alignment","Female","Age x Female","Intercept", "Mother's Education", "Age x Mother's Education","Parent Alignment","Age x Parent Alignment")

order <- c("Intercept","Age (years)", "Female","Age x Female","Mother's Education", "Age x Mother's Education","Child Alignment","Age x Child Alignment", "Parent Alignment","Age x Parent Alignment")
  

ppvt_parameters %>% 
  mutate(parameter = replace(parameter, parameter == 'ppvt_education', "ppvt_mother_ed")) %>% 
  arrange(parameter) %>% 
  mutate(parameter = ppvt_coefficients) %>% 
  mutate(Estimate = mean) %>% 
  select(parameter,Estimate) %>% 
  slice(match(order, parameter)) %>%
  xtable::xtable(., digits=2,caption = 'Parameter Estimates for PPVT predictors with standard errors.') %>% 
  print(., type="latex", comment = F, table.placement = "H", sanitize.text.function = function(x){x})

# demotable <- demoparameters %>% 
#   mutate(measure = replace(measure, measure == 'ppvt_education', "ppvt_mother_ed")) %>% 
#   arrange(measure) %>% 
#   mutate(StandardError = (se_upper-se_lower)/2,
#          Estimate = mean) %>% 
#   select(measure,Estimate, StandardError) %>% 
#   xtable::xtable(., digits=2,caption = 'Parameter Estimates for PPVT predictors with standard errors.')
# 
# print(demotable, type="latex", comment = F, table.placement = "H", sanitize.text.function = function(x){x})
```


```{r hpds, fig.env = "figure*", fig.width=7, fig.height=2.75, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Model-estimated changes in linguistic alignment over development. Points indicate the mean of the posterior distribution, shaded regions indicate 68\\% highest probability density intervals, equivalent to one standard deviation", cache = T}
ages <- tibble(session = 1:12) %>%
  ungroup() %>%
  distinct(session) %>%
  mutate(age = 14 + 4*(session - 1))

mid_age <- mean(ages$session)

hpds <- map(1:nrow(ages), 
            function(x) mutate(subpop_samples, age_num = x)) %>%
  bind_rows() %>%
  group_by(person, age_num) %>%
  mutate(age_dif = age_num - mid_age) %>%
  mutate(prediction = eta_ab_subpop + ((age_num-mid_age) * alpha_subpop)) %>%
  summarize(mean = mean(prediction), se_lower = quantile(prediction, SE_LOWER), 
                      se_upper = quantile(prediction, SE_UPPER)) %>%
  left_join(ages, by = c("age_num" = "session"))

 ggplot(hpds, aes(x = age, y = mean, label = person, 
            group = person, color = person, fill = person)) + 
   geom_point(size = 2) +
   geom_ribbon(aes(ymax = se_upper, ymin = se_lower),
               alpha = .3, size = 0) +
   geom_line() +
   scale_color_ptol(guide = FALSE) +
   scale_fill_ptol(guide = FALSE) +
   theme_classic(base_size = 14) +
   scale_x_continuous(name = "Child\'s Age (months)",
                      breaks=seq(12,60,6), limits = c(10, 60)) +
   scale_y_continuous(limits = c(-.8, 1.8), breaks = seq(-.5,1.8,.5),
                     name = "Linguistic Alignment") +
   geom_hline(yintercept=0,linetype='dashed') +
   theme(legend.position = "none",
         axis.title.x=element_text(vjust=-.5), axis.title.y=element_text(vjust=1)) +
     geom_dl(method = list(dl.trans(x = x -.2), "first.qp", cex=1))
``` 
  

```{r demopar_plot, fig.width=3.5, fig.height=2.25, set.cap.width=T, num.cols.cap=1, cache = T, fig.cap = "Posterior parameter estimates for demographic effects on PPVT scores. Points indicate means, error-bars indicate 95\\% highest posterior density intervals"}
plot_ppvt_parameters <- ppvt_parameters %>%
  mutate(parameter = gsub("ppvt_", "", parameter),
         component = if_else(str_detect(parameter, "slope"), "Gain in PPVT", "PPVT Score"),
         component = factor(component, levels = c("PPVT Score", "Gain in PPVT")),
         person = if_else(str_detect(parameter, "parent"), "parent", "child")) %>%
  mutate(parameter = case_when(parameter == "age_years" ~ "age (years)",
                               str_detect(parameter, "align") ~ "alignment",
                               parameter == "mother_ed_slope" ~ "education",
                               parameter == "female_slope" ~ "female",
                               T ~ parameter)) %>%
  filter(parameter != "intercept") 

ggplot(plot_ppvt_parameters, aes(x = parameter, y = mean, ymin = ci_lower, ymax = ci_upper,
                                 color = person)) + 
  facet_wrap(~ component) +
  geom_pointrange(position = position_dodge(.5)) + 
  geom_hline(aes(yintercept = 0), linetype = "dashed") +
  coord_flip() + 
  scale_colour_ptol() + 
  theme_classic(base_size=9) + 
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_text(size=6))

```
# Discussion
  In an effort to understand and investigate how children rapidly acquire language, some argue that the language parents produce to their children is somehow calibrated to the child's particular needs and abilities [@Snow:2018wf]. While the idea is theoretically compelling, empirical work has produced mixed results, with strong results in favor of [@Chouinard:2003kq; @HirshPasek:1984bd] and against [@Brown:1970wd; @Hayes:1988ue].
  
However, much of this prior work investigates tuning as an overt effort on behalf of parents or tuning with respect to content words, with less examining the potential role of low-level syntactic influence [@Hoff:2003kx]. @Anonymous:r2JoRscQ presents just such an examination, demonstrating using Bayesian hierarchical modeling that parents align to their children according to their particular language usage at the level of syntactic categories. This paper extends their model by applying it to a new socioeconomically diverse sample of families [@GoldinMeadow:2014hr] and leveraging the model's alignment estimates to predict language development outcomes.  
  
The analysis presented here replicates the findings of @Anonymous:r2JoRscQ, showing strong alignment effects for both parents and their children, a substantial age effect for baseline useage in children, and a trending negative effect of age on alignment for parents. Moreover, we demonstrate that these alignment estimates have substantial power in predicting language development outcomes, even in the presence of demographic features such as gender and socioeconomic status. We corroborate previous findings that female children tend to have higher PPVT scores that diminish over time [@Lange:2016gv; @Kaushanskaya:2013gi]. We conflict with other findings that positively associate child PPVT scores with mother's education [@DiCesare:2013ip; @Schady:2011bb]; this may be due to idiosyncracies of our dataset, including its limited size. 

  We show that parental alignment is associated with a relatively large boost in overall PPVT scores, but with a negative age effect. The negative age effect may source from a ceiling on PPVT - children with higher scores may simply have less ground to cover. Nevertheless, these results are consistent with a concrete effect of parental alignment on language development, and the linguistic tuning hypothesis more broadly. A similar story is evident from child alignment estimates: alignment has a small association with overall PPVT score and an age effect comparable to parental alignment. Here there may be a confound with childrens' baseline language production, in that children with lower production will have lower PPVT and diminished alignment as a result; future work should assess this interaction to better isolate the effects of alignment. 
  
  Overall, these results show that parental alignment is a robust effect that appears to have a relationship with childrens' language development independent of demographic correlates, serving to further the linguistic tuning hypothesis. 
  

  
  
  
<!-- The entire content of a paper (including figures, references, and anything else) can be no longer than six pages in the \textbf{initial submission}. In the \textbf{final submission}, the text of the paper, including an author line, must fit on six pages. Up to one additional page can be used for acknowledgements and references. -->

<!-- The text of the paper should be formatted in two columns with an -->
<!-- overall width of 7 inches (17.8 cm) and length of 9.25 inches (23.5 -->
<!-- cm), with 0.25 inches between the columns. Leave two line spaces -->
<!-- between the last author listed and the text of the paper; the text of -->
<!-- the paper (starting with the abstract) should begin no less than 2.75 inches below the top of the -->
<!-- page. The left margin should be 0.75 inches and the top margin should -->
<!-- be 1 inch.  \textbf{The right and bottom margins will depend on -->
<!-- whether you use U.S. letter or A4 paper, so you must be sure to -->
<!-- measure the width of the printed text.} Use 10~point Times Roman -->
<!-- with 12~point vertical spacing, unless otherwise specified. -->

<!-- The title should be in 14~point bold font, centered. The title should -->
<!-- be formatted with initial caps (the first letter of content words -->
<!-- capitalized and the rest lower case). In the initial submission, the -->
<!-- phrase ``Anonymous CogSci submission'' should appear below the title, -->
<!-- centered, in 11~point bold font.  In the final submission, each -->
<!-- author's name should appear on a separate line, 11~point bold, and -->
<!-- centered, with the author's email address in parentheses. Under each -->
<!-- author's name list the author's affiliation and postal address in -->
<!-- ordinary 10~point type. -->

<!-- Indent the first line of each paragraph by 1/8~inch (except for the -->
<!-- first paragraph of a new section). Do not add extra vertical space -->
<!-- between paragraphs. -->


<!-- # First-Level Headings -->

<!-- First level headings should be in 12 point , initial caps, bold and -->
<!-- centered. Leave one line space above the heading and 1/4~line space -->
<!-- below the heading. -->

<!-- ## Second-Level Headings -->

<!-- Second level headings should be 11 point , initial caps, bold, and -->
<!-- flush left. Leave one line space above the heading and 1/4~ line -->
<!-- space below the heading. -->

<!-- ### Third-Level Headings -->

<!-- Third-level headings should be 10 point , initial caps, bold, and flush -->
<!-- left. Leave one line space above the heading, but no space after the -->
<!-- heading. -->

<!-- # Formalities, Footnotes, and Floats -->

<!-- Use standard APA citation format. Citations within the text should -->
<!-- include the author's last name and year. If the authors' names are -->
<!-- included in the sentence, place only the year in parentheses, as in -->
<!-- [-@NewellSimon1972a], but otherwise place the entire reference in -->
<!-- parentheses with the authors and year separated by a comma -->
<!-- [@NewellSimon1972a]. List multiple references alphabetically and -->
<!-- separate them by semicolons [@ChalnickBillman1988a; @NewellSimon1972a].  -->
<!-- Use the et. al. construction only after listing all the authors to a -->
<!-- publication in an earlier reference and for citations with four or -->
<!-- more authors. -->

<!-- For more information on citations in RMarkdown, see **[here](http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html#citations).** -->

<!-- ## Footnotes -->

<!-- Indicate footnotes with a number\footnote{Sample of the first -->
<!-- footnote.} in the text. Place the footnotes in 9 point type at the -->
<!-- bottom of the page on which they appear. Precede the footnote with a -->
<!-- horizontal rule.\footnote{Sample of the second footnote.} You can also use  -->
<!-- markdown formatting to include footnotes using this syntax [^1]. -->

<!-- [^1]: Sample of a markdown footnote. -->

<!-- ## Figures -->

<!-- All artwork must be very dark for purposes of reproduction and should -->
<!-- not be hand drawn. Number figures sequentially, placing the figure -->
<!-- number and caption, in 10 point, after the figure with one line space -->
<!-- above the caption and one line space below it. If necessary, leave extra white space at -->
<!-- the bottom of the page to avoid splitting the figure and figure -->
<!-- caption. You may float figures to the top or bottom of a column, or -->
<!-- set wide figures across both columns. -->

<!-- ## Two-column images -->

<!-- You can read local images using png package for example and plot  -->
<!-- it like a regular plot using grid.raster from the grid package.  -->
<!-- With this method you have full control of the size of your image. **Note: Image must be in .png file format for the readPNG function to work.** -->

<!-- You might want to display a wide figure across both columns. To do this, you change the `fig.env` chunk option to `figure*`. To align the image in the center of the page, set `fig.align` option to `center`. To format the width of your caption text, you set the `num.cols.cap` option to `2`. -->

<!-- ```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."} -->
<!-- img <- png::readPNG("figs/walrus.png") -->
<!-- grid::grid.raster(img) -->
<!-- ``` -->

<!-- ## One-column images -->

<!-- Single column is the default option, but if you want set it explicitly, set `fig.env` to `figure`. Notice that the `num.cols` option for the caption width is set to `1`. -->

<!-- ```{r image, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "One column image."} -->
<!-- img <- png::readPNG("figs/lab_logo_stanford.png") -->
<!-- grid::grid.raster(img) -->
<!-- ``` -->


<!-- ## R Plots -->

<!-- You can use R chunks directly to plot graphs. And you can use latex floats in the -->
<!-- fig.pos chunk option to have more control over the location of your plot on the page. For more information on latex placement specifiers see **[here](https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions)** -->

<!-- ```{r plot, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2, fig.height=2, fig.cap = "R plot" } -->
<!-- x <- 0:100 -->
<!-- y <- 2 * (x + rnorm(length(x), sd = 3) + 3) -->

<!-- ggplot2::ggplot(data = data.frame(x, y),  -->
<!--                 aes(x = x, y = y)) +  -->
<!--   geom_point() +  -->
<!--   geom_smooth(method = "lm") -->
<!-- ``` -->


<!-- ## Tables -->

<!-- Number tables consecutively; place the table number and title (in -->
<!-- 10 point) above the table with one line space above the caption and -->
<!-- one line space below it, as in Table 1. You may float -->
<!-- tables to the top or bottom of a column, set wide tables across both -->
<!-- columns. -->

<!-- You can use the xtable function in the xtable package. -->

<!-- ```{r xtable, results="asis"} -->
<!-- n <- 100 -->
<!-- x <- rnorm(n) -->
<!-- y <- 2*x + rnorm(n) -->
<!-- out <- lm(y ~ x) -->

<!-- tab1 <- xtable::xtable(summary(out)$coef, digits=c(0, 2, 2, 1, 2),  -->
<!--                        caption = "This table prints across one column.") -->

<!-- print(tab1, type="latex", comment = F, table.placement = "H") -->
<!-- ``` -->

<!-- # Acknowledgements -->

<!-- Place acknowledgments (including funding information) in a section at -->
<!-- the end of the paper. -->

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
