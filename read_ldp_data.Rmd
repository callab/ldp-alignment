---
title: Linguistic Alignment in LDP
author: Jo Denby, Ashley Leung, and Dan Yurovksy
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show
---

```{r setup, include = FALSE}
library(knitr)
library(data.table)
library(tidyverse)
library(readr)
library(stringr)
library(DT)
library(tidytext)
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
               error = FALSE, cache = TRUE, tidy = FALSE)
```


Read in LDP data. Don't display in public repo
```{r read_ldp}
LDP_DIR <- "~/Documents/LDP/ldp.db"
#LDP_DIR <- "~/ldp/data/ldp.db"

# Read in LDP data
ldp <- src_sqlite(LDP_DIR)

# Get all participants
subjs <- tbl(ldp, "subjects") %>%
  collect()

# Get visit data
visits <- tbl(ldp, "visits") %>%
  collect() %>%
  select(subject, session, date, child_age, child_age_years, child_age_months,
         income, mother_education, father_education)
```

Read in LIWC Categories
```{r read_liwc}
liwc <- read_tsv("word_lists/liwc2007_converted.tsv", col_names = FALSE) %>%
  rename(word = X1, category = X2)
```

Set up utterances for computing alignment
```{r setup_alignment}
# What do we do when both participants talk on the same line
utterances <- tbl(ldp, "utterances") %>%
  select(subject, session, line, p_chat, c_chat) %>%
  filter(p_chat != "" | c_chat != "") %>%
  collect() %>%
  mutate(order = 1:n())
  
#utterances <- mutate(utterances,order = seq.int(nrow(utterances)))

#use rleid from data table to do squashing by run
split_utts <- utterances %>%
  gather(person, chat, c(p_chat, c_chat)) %>%
  mutate(person = if_else(person == "p_chat", "Parent", "Child")) %>%
  filter(chat != "") %>%
  arrange(order) %>%
  mutate(run = rleid(subject, session, person)) %>%
  group_by(run, subject, session, person) %>%
  summarise(chat = paste0(chat, collapse = " ")) 

tokens <- split_utts %>%
  unnest_tokens(word, chat) %>%
  arrange(run, subject, session) %>%
  group_by(subject, session)

#WRONG for regular expressions
# use grep
present <- map(1:2, function(row) {
  data_frame(present = tokens$word == as.character(liwc[row, "word"]))
}) %>%
  bind_cols() 
names(present) = pull(liwc, word)[1:2]


long_present <- present %>%
    slice(1:10) %>%
  bind_cols(tokens) %>%
  gather(liwc_word, count, names(present)) %>%
  left_join(liwc, by = c("liwc_word" = "word")) %>%
  group_by(subject, session, person, category) %>%
  summarise(count = sum(count)) %>%
  

# 
# person <- c('c', 'p', 'p', 'p')
# chatters <- c('blah', 'flerg', 'hmm', 'wow')
# df <- data_frame(person, chatters)
# 
# findRuns <- function(check, utt, super_utt) {
#   #check ifelse person is same
#   tmp <- ifelse(check == lag(check),  
#               #recursively call function, with lagged arguments and updated super_utt
#                findRuns(lag(check), 
#                           lag(utt), 
#                           paste(super_utt, utt)), 
#               #otherwise, just update the super utt
#                paste(super_utt, utt))
#   #final check, to see if above lines return NA, in which case return unchanged utt
#   ifelse(is.na(tmp), utt, tmp)
# }
# 
# df_new <- df %>%
#   mutate(new= findRuns(person, chatters, ''))
#   
# 
# flat_utt <- split_utts %>%
#   mutate(new= findRuns(person, chat, ''))
# Throws error ??

# findRuns <- function(person,chat, super_utt) {
#   if (is.na(lag(person))){
#     return(super_utt)
#     print('no person!')
#     count <- 0
#   }
#   else if (person==lag(person)) {
#     super_utt <- paste(super_utt,lag(chat),sep=" ")
#     print(super_utt)
#     count <- count + 1
#     findRuns(lag(person), lag(chat),super_utt)
#   }
#   else {
#     if (count == 0){
#       super_utt <-lag(chat)
#       print('no count!')
#     }
#     return(super_utt)
#     count <- 0
#     print('well at least there\'s a count!')
#   }
# }

# split_utts_fixed <- split_utts %>%
  # mutate(super_chat = findRuns(person, chat, ''))
# mutate(n_back = findRuns(typedLabel, 0)) %>%
  

# Now want to:
# 1. flatten all successive utterances from the same person
# 2. Count the number of appearances of each target word in each utterances
# 3. At a lag of one (use the lag function), check if the previous speaker's utterance contained each word
# 4. aggregate!
```